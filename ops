{"author":{"id":"2925f8bae681ccf02a1c1ecc82cbb827e525744b16a0948b37a0b024362c4ec0"},"ops":[{"type":1,"timestamp":1670626038,"nonce":"jmEDqsdxVitOL7c3p4f/DfnWBbs=","title":"performance","message":"(using large model, 2.4M params)\n\nmodel creation vs run batch\n\n```julia\njulia\u003e @btime models = Dict(\"f0a0\"=\u003ere(reconstruct(nt, UInt32.([3, 4, 5]))))\n3.576 ms (436 allocations: 28.27 MiB)\njulia\u003e @btime rewards, mets, bc = run_batch(env, models, args)\n472.274 ms (126467 allocations: 335.63 MiB)\n```\n\nmodel creation scales with seed count\n\n```julia\njulia\u003e @btime models = Dict(\"f0a0\"=\u003ere(reconstruct(nt, UInt32.([rand([1,2,3]) for _ in 1:100]))))\n  60.308 ms (536 allocations: 28.28 MiB)\n```\n\nre adds negligible overhead \n```\njulia\u003e @btime reconstruct(nt, UInt32.([1,2,3,4,5,6,7,8,9,10]));\n  6.779 ms (7 allocations: 18.83 MiB)\n@btime re(reconstruct(nt, UInt32.([1,2,3,4,5,6,7,8,9,10])));\n  7.453 ms (431 allocations: 28.26 MiB)\n\n```","files":null}]}